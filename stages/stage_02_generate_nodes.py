import pandas as pd
import logging
from pathlib import Path
import json
from utils.constants import (
    PROCESSED_DIR, FILTERED_SUB_NETWORK_POLYGON_FILE, PLATFORM_FILE, STATION_HELPER_FILE, STATION_ENTRY_NODE_FILE
)
from utils.platform_ops import (
    filter_perron_data, process_station_platform_info, find_station_connections, define_station_types, assign_center_coordinates, compute_entry_nodes_json
)

def setup_logger(debug_mode=False):
    """
    Setup logger with INFO or DEBUG level.

    Args:
        debug_mode (bool): Whether to enable debug mode.

    Returns:
        logging.Logger: Configured logger.
    """
    logger = logging.getLogger(__name__)
    if not logger.hasHandlers():
        handler = logging.StreamHandler()
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
    logger.setLevel(logging.DEBUG if debug_mode else logging.INFO)
    return logger

def run(debug=False):
    """
    Stage 02: Decide Platform Length for Sub-Network Stations.

    Args:
        debug (bool): Enable debug logging.
    """
    logger = setup_logger(debug)
    logger.info("üöÄ Stage 02 started: Decide Platform Length for Sub-Network Stations")

    # Ensure processed directory exists
    PROCESSED_DIR.mkdir(parents=True, exist_ok=True)

    try:
        # 1Ô∏è‚É£ Load raw data
        platform_cols_to_read = [
            'Line', 'Station abbreviation', 'Customer track number',
            'Platform number', 'Length of platform edge'
        ]
        polygon_df = pd.read_csv(FILTERED_SUB_NETWORK_POLYGON_FILE, delimiter=';')
        perron_df = pd.read_csv(PLATFORM_FILE, delimiter=';', usecols=platform_cols_to_read)

        # 2Ô∏è‚É£ Prepare unique stations
        unique_ops = set(polygon_df["START_OP"]).union(polygon_df["END_OP"])

        # 3Ô∏è‚É£ Filter perron data
        perron_df_filtered = filter_perron_data(perron_df, unique_ops)

        logger.info(f"üîé Filtered perronkante by Station abbreviation: {len(set(perron_df_filtered['Station abbreviation']))} unique stations")
        logger.info(f"üì• Loaded sub_network polygon file: {FILTERED_SUB_NETWORK_POLYGON_FILE} ({len(unique_ops)} unique stations)")

        # 4Ô∏è‚É£ Process platform information
        platform_df = process_station_platform_info(perron_df_filtered, unique_ops, logger)
        platform_df = find_station_connections(platform_df)
        platform_df = define_station_types(platform_df)
        platform_df = assign_center_coordinates(platform_df, logger)
        entry_node_data  = compute_entry_nodes_json(platform_df, logger)
        
        # 5Ô∏è‚É£ Save result
        
        platform_df.to_csv(STATION_HELPER_FILE, index=False, encoding='utf-8-sig')
        logger.info(f"‚úÖ Saved platform info to: {STATION_HELPER_FILE.resolve()}")
        with open(STATION_ENTRY_NODE_FILE, 'w', encoding='utf-8') as f:
            json.dump(entry_node_data, f, indent=4, ensure_ascii=False)

        logger.info(f"‚úÖ Saved entry node coordinates to: {STATION_ENTRY_NODE_FILE.resolve()}")

    except Exception as e:
        logger.error(f"‚ùå Stage 02 failed: {e}")
        return
